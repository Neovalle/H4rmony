{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVuucZQ8ZDanvtQRMHYzWG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neovalle/H4rmony/blob/main/Imploding_and_Exploding_H4rmony_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting the dataset to rows of unique Prompt and Completions (Imploding)"
      ],
      "metadata": {
        "id": "NsfRDGYrv7GX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaQfJS5jr0bn"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"neovalle/H4rmony\")\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "df = pd.DataFrame(dataset['train'])\n",
        "\n",
        "# Proceed with the dataset transformation\n",
        "# Filter rows for 'R1-R2' and 'R1-R3' ComparedRanks\n",
        "df_r1_r2 = df[df['ComparedRanks'] == 'R1-R2']\n",
        "df_r1_r3 = df[df['ComparedRanks'] == 'R1-R3']\n",
        "\n",
        "# Create a dictionary to hold the new dataset\n",
        "new_data = {\n",
        "    'PromptID': [],\n",
        "    'Prompt': [],\n",
        "    'BetterAnswer': [],\n",
        "    'Ambivalent': [],\n",
        "    'WorseAnswer': []\n",
        "}\n",
        "\n",
        "# Populate the dictionary\n",
        "for prompt_id in df['PromptID'].unique():\n",
        "    prompt = df[df['PromptID'] == prompt_id]['Prompt'].iloc[0]\n",
        "\n",
        "    better_answer = df_r1_r2[df_r1_r2['PromptID'] == prompt_id]['BetterCompletion'].iloc[0] if not df_r1_r2[df_r1_r2['PromptID'] == prompt_id].empty else None\n",
        "    ambivalent = df_r1_r2[df_r1_r2['PromptID'] == prompt_id]['WorseCompletion'].iloc[0] if not df_r1_r2[df_r1_r2['PromptID'] == prompt_id].empty else None\n",
        "    worse_answer = df_r1_r3[df_r1_r3['PromptID'] == prompt_id]['WorseCompletion'].iloc[0] if not df_r1_r3[df_r1_r3['PromptID'] == prompt_id].empty else None\n",
        "\n",
        "    new_data['PromptID'].append(prompt_id)\n",
        "    new_data['Prompt'].append(prompt)\n",
        "    new_data['BetterAnswer'].append(better_answer)\n",
        "    new_data['Ambivalent'].append(ambivalent)\n",
        "    new_data['WorseAnswer'].append(worse_answer)\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "new_df = pd.DataFrame(new_data)\n",
        "\n",
        "# new_df.to_csv('transformed_dataset.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the dataset pairwise (exploding)"
      ],
      "metadata": {
        "id": "3-O0xYfQvX0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a new DataFrame to hold the rebuilt dataset\n",
        "rebuilt_df = pd.DataFrame(columns=['PromptID', 'Prompt', 'BetterCompletion', 'WorseCompletion', 'ComparedRanks'])\n",
        "\n",
        "# Iterate through new_df to rebuild the original structure\n",
        "for _, row in new_df.iterrows():\n",
        "    # Row for ComparedRanks = 'R1-R2'\n",
        "    rebuilt_df = rebuilt_df.append({\n",
        "        'PromptID': row['PromptID'],\n",
        "        'Prompt': row['Prompt'],\n",
        "        'BetterCompletion': row['BetterAnswer'],\n",
        "        'WorseCompletion': row['Ambivalent'],\n",
        "        'ComparedRanks': 'R1-R2'\n",
        "    }, ignore_index=True)\n",
        "\n",
        "    # Row for ComparedRanks = 'R1-R3'\n",
        "    rebuilt_df = rebuilt_df.append({\n",
        "        'PromptID': row['PromptID'],\n",
        "        'Prompt': row['Prompt'],\n",
        "        'BetterCompletion': row['BetterAnswer'],\n",
        "        'WorseCompletion': row['WorseAnswer'],\n",
        "        'ComparedRanks': 'R1-R3'\n",
        "    }, ignore_index=True)\n",
        "\n",
        "    # Row for ComparedRanks = 'R2-R3'\n",
        "    rebuilt_df = rebuilt_df.append({\n",
        "        'PromptID': row['PromptID'],\n",
        "        'Prompt': row['Prompt'],\n",
        "        'BetterCompletion': row['Ambivalent'],\n",
        "        'WorseCompletion': row['WorseAnswer'],\n",
        "        'ComparedRanks': 'R2-R3'\n",
        "    }, ignore_index=True)\n",
        "\n",
        "\n",
        "# rebuilt_df.to_csv('rebuilt_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "id": "C_qmi4lBu9w5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}